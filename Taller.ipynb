{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ca522f3",
   "metadata": {},
   "source": [
    "<summary>\n",
    "    <font size=\"8\" color=\"gray\"><b> Taller\n",
    " </b></font>\n",
    "</summary>\n",
    "<summary>\n",
    "    <font size=\"4\" color=\"orange\"><b> Autocorrector ortográfico en español\n",
    " </b></font>\n",
    "</summary>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"gray\"><b> VII Edición  del  Congreso  de  Estudiantes  de  Ingeniería  de  la  Universidad  del  Caribe\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "\n",
    "---\n",
    " \n",
    "<summary>\n",
    "    <font size=\"2\" color=\"gray\"><b> Olivia Gutú\n",
    " </b></font>\n",
    " <summary>\n",
    "    <font size=\"2\" color=\"gray\"><b> olivia.gutu@unison.mx\n",
    " </b></font>   \n",
    " </summary>  \n",
    "    \n",
    "---\n",
    "\n",
    "<summary>\n",
    "    <font size=\"1\" color=\"gray\"><b> Noviembre 2023\n",
    " </b></font>\n",
    " </summary>  \n",
    "\n",
    " <p><font size=\"2\" color=\"gray\">\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/mcd-unison/corrector-ortografico/blob/main/Taller.ipynb\"><img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\"  width=\"50\" /> <br>Ejecuta en Colab</a>\n",
    " </font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ca0ecf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# ¿Cómo funciona un corrector ortográfico?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1db517",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* **Se crea un vocabulario**: \n",
    "\n",
    "A partir de un corpus se fija un vocabulario\n",
    " \n",
    "* **Identifica la palabra incorrecta $w$**: \n",
    " \n",
    "Identificamos que una palabra es incorrecta, es decir, no se encuentra dentro de nuestro vocabulario.\n",
    " \n",
    "* **Se filtran los posibles candidatos**: \n",
    " \n",
    "Usualmente, se calculan las palabras a 1, 2 o 3 de distancia en términos del número mínimos de pasos de edición (*deletes*, *replaces*, *inserts*) que se necesitan para transformar una palabra a otra. Se filtran los posibles candidatos de manera que se encuentren dentro de nuestro vocabulario.\n",
    "    \n",
    "* **Se calcula el más probable en funcion del corpus**\n",
    "\n",
    "Se encuentra la corrección $c$, de todos los candidatos, de forma que maximize la probabilidad de que $c$ sea la palabra correcta. La probabilidad se estima a partir de un «modelo probabilístico» que nos dará los criterios específicos para hacer los cálculos correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc9922",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Elementos de un modelo probabilístico generativo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698172d6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La parte fundamental de un corrector ortográfico es dada una palabra errónea $w$ econtrar la mejor  corrección $c$ dentro de un conjunto de cantidatos: \n",
    "\n",
    "$$c_{mejor~corrección} = argmax_{c \\in candidatos} P(c|w)$$\n",
    "\n",
    "Por ejemplo, $P(\\mbox{Dulcinea}|\\mbox{Dulsinea})$ se puede interpretar como las veces en que  $\\mbox{Dulcinea}$\n",
    "es la corrección del error $\\mbox{Dulsinea}$. De la misma manera $P(\\mbox{Dulcine}|\\mbox{Dulsinea})$ las veces que $\\mbox{Dulcine}$ es la corrección del error $\\mbox{Dulsinea}$. Estas probabilidades son dependientes del corpus de apoyo para estimar estas probabilidades.\n",
    "\n",
    "El punto de vista generativo plantea estimar esta probabilidad a partir del teorema de Bayes (ver https://www.youtube.com/watch?v=HZGCoVF3YvM):\n",
    "\n",
    "$$P(c|w) =  P(c) \\dfrac{P(w|c)}{P(w)}.$$\n",
    "\n",
    "Tenemos en esta formulación los siguientes elementos:\n",
    "\n",
    "* $P(c|w)$ (p. posterior) la probabilidad del candidato $c$  dado el error $w$: **probabilidad de que la hipótesis $c$ es correcta dada la evidencia $w$.**\n",
    "\n",
    "* $P(c)$ (prior) la probabilidad previa del candidato $c$ antes de que se observe cualquier error $w$: **probabilidad de la hipótesis $c$ antes de cualquier evidencia $w$.**\n",
    "\n",
    "* $P(w|c)$ (verosimilitud) la probabilidad de la palabra $w$  dado el candidato $c$: **probabilidad de ver la evidencia $w$ si la hipótesis $c$ es cierta.**\n",
    "\n",
    "* $P(w)$ (evidencia): **probabilidad de que la evidencia es cierta.**\n",
    "\n",
    "\n",
    "Como $P(w)$ es independiente de cualquier candidato $c$, podemos finalmente considerar el siguiente problema de optimización:\n",
    "\n",
    "$$c_{mejor~corrección} = argmax_{c \\in candidatos} P(c) P(w|c)$$\n",
    "\n",
    "\n",
    "Visto de esta manera, en la ecuación de arriba aparecen 4 elementos escenciales de un modelo de autocorrector:\n",
    "\n",
    "---\n",
    "\n",
    "* **Selección de mecanismo**: $argmax$\n",
    "\n",
    "Se elige al candidato con mayor probabilidad.\n",
    "\n",
    "* **Modelo de candidato**: conjunto $candidatos$\n",
    "\n",
    "Nos dice qué correcciones candidatos $c$ considerar.\n",
    "\n",
    "* **Modelo de lenguaje**: $P(c)$\n",
    "\n",
    "La probabilidad de que $c$ aparezca en el idioma español. \n",
    "\n",
    "* **Modelo de error**: $P(w|c)$\n",
    "\n",
    "La probabilidad de que $w$ se escriba en un texto cuando el autor quiso decir $c$.\n",
    "\n",
    "---\n",
    "\n",
    "Por ejemplo, `P(Dulsine|Dulcinea` se puede interpretar como de las veces que se escribió `Dulsinea` dentro de las veces que se quiso escribir `Dulcinea}`. En este contexto`P(Dulce|Dulcinea)` debería ser mucho menor que `P(Dulsinea|Dulcinea`, es decir `Dulce` es un error menos común que `Dulsinea` como errores de `Dulcinea`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c6c90",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Metodología para la creación de un autocorrector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f77316",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1.  Obtención del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238d58d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "Para este taller vamos a entrenar nuestro corrector ortográfico con El Quijote. El corpus se ha descargado de\n",
    "https://fegalaz.usc.es/~gamallo/aulas/lingcomputacional/corpus/quijote-es.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94b3ba",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La idea es estimar probabilidad de una palabra, $P(w)$ (modelo de lenguaje), contando el número de veces que aparece cada palabra en el archivo **quijote-es.txt**. Sin embargo este es un ejemplo de juguete ya que una estimación más precisa debe considerar al menos $1\\times 10^9$ de palabras distintas. \n",
    "\n",
    "Ademas, el texto es muy específico a un momento histórico y geográfico, así que no sería una buen corpus para un corrector actual.  Por otro lado, ¡no tenemos corpus para estimar $P(w|c)$! pues tenemos necesitaríamos datos sobre la frecuencia con las que un habitante del reino de  Castilla y León del siglo XVII comete errores ortográficos y cuáles son estos. Ese tipo de conjuntos es difícil encontrarlos incluso en el español actual. Veremos más adelantes como sortear este problema. En inglés existe por ejemplo el  Birkbeck spelling error corpus https://www.dcs.bbk.ac.uk/~roger/corpora.html. Ver también https://en.wikipedia.org/wiki/Wikipedia:Lists_of_common_misspellings/For_machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d6dc60",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. Creación de vocabulario y análisis exploratorio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b2ca0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Primero se va a construir una función `words` para tokenizar cualquier texto, esta tokenización se hace de la manera más sencilla posible considerando la expresión regular **'\\w+'** (ver  https://docs.python.org/3/library/re.html para más sobre expresiones regulares). Una vez tokenizado nuestro texto `quijote.txt` se crea, no solo un el vocabulario, si no un diccionario de frecuencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b34de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())  \n",
    "\n",
    "WORDS = Counter(words(open('quijote.txt', encoding='latin-1').read())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f471f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d71c7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nuesto diccionario de frecuencias contiene el **vocabulario** y también la frecuencia de cada **tipo**, lo que nos servirá más adelante para estimar la probabildad de una palabra. Un **token** es una instancia de una secuencia de caracteres en algún documento en particular que se agrupan como una unidad semántica útil para el procesamiento. Un **tipo** es la clase de todos los tokens diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a5d01",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "WORDS.most_common(30) ## los 30 tipos más frecuentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078dc364",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La **longitud del corpus** (`N`) es suma de frecuencias de tokens de nuestro diccionario de frecuencias y la **cardinalidad del vocabulario** (`V`)  es la cardinalidad del vocabulario de tipos, la cual coincide con la del propio diccionario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbaac1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = sum(WORDS.values()) \n",
    "V = len(WORDS)\n",
    "print('Longitud de El Quijote (N): ' + str(N) + '\\n' + 'Tamaño del vocabulario del El Quijote (V): ' + str(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3dca6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Análisis de datos**\n",
    "\n",
    "Aquí un pequeño análisis de la distribución de los valores del diccionario de frecuencias. Corre y analiza los resultados de los histogramas que se presentan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d109ea9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "WORDS_valores_pequeños = dict([(key, val) for key, val in WORDS.items() if 1 <= val <= 10])\n",
    "x = list(WORDS_valores_pequeños.values())\n",
    "fig = px.histogram(x, text_auto=True, title='Histograma de frecuencias de palabras en El Quijote que aparecen de 1 a 10 veces')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7215104",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "WORDS_valores_medianos = dict([(key, val) for key, val in WORDS.items() if 10 <= val <= 200])\n",
    "x = list(WORDS_valores_medianos.values())\n",
    "fig = px.histogram(x, text_auto=True, title='Histograma de frecuencias de palabras en El Quijote que aparecen de 10 a 200 veces')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46b95a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "WORDS_valores_grandes = dict([(key, val) for key, val in WORDS.items() if 200 <= val <= 2500])\n",
    "x = list(WORDS_valores_grandes.values())\n",
    "fig = px.histogram(x, text_auto=True, title='Histograma de frecuencias de palabras en El Quijote que aparecen de 200 a 2500 veces')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cb1a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "WORDS_valores_muy_muy_grandes = dict([(key, val) for key, val in WORDS.items() if 8000 <= val <= 21000])\n",
    "x = list(WORDS_valores_muy_muy_grandes.values())\n",
    "fig = px.histogram(x, text_auto=True, title='Histograma de frecuencias de palabras en El Quijote que aparecen de 8000 a 21000 veces')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1fb5a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Hápax y riqueza léxica**\n",
    "\n",
    "Según el diccionario Oxford **hápax** es hápax *una palabra o expresión que solo se encuentra documentada una vez en una lengua, un autor o un texto* e.g. «la edición crítica de los autores clásicos permite en muchas ocasiones aclarar si determinadas palabras son realmente hápax o se trata de erratas de los copistas»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5cb600",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "WORDS_hapax = dict([(key, val) for key, val in WORDS.items() if  val == 1])\n",
    "WORDS_hapax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8bfcf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "¿Qué proporción de hápax hay en El Quijote?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8c6aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tasa_hápax = len(WORDS_hapax)/V\n",
    "print('Tasa de hápax: ' + str(tasa_hápax) + ' 🤨')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b136053",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Índice de riqueza léxica:**\n",
    "    $$H = 100 \\frac{\\log (\\mbox{tamaño corpus})}{1-\\mbox{tasa_hápax}}.$$\n",
    "Para nuestro corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0796bf9c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "H = 100 * np.log(N)/(1-tasa_hápax)\n",
    "\n",
    "print('Índice de riqueza léxica de (todo) El Quijote: ' + str(H.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0e356",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Close up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cdee7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "skip_min =  WORDS['dulcinea']\n",
    "skip_max = WORDS['quijote']\n",
    "WORDS_reducido = dict([(key, val) for key, val in WORDS.items() if skip_min <= val <= skip_max])\n",
    "vocabulario_reducido = pd.DataFrame(WORDS_reducido.items(), columns = ['palabra','frecuencia']).sort_values(by='frecuencia')\n",
    "fig = px.bar(vocabulario_reducido, x='palabra', y='frecuencia', color = 'frecuencia')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a249fc2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 0\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "Repite este ejercicio pero con *Cien años de soledad* (se anexa el archivo `cien-años-de-soledad.txt`) ¿Cuál de los dos textos tiene mayor riquiza léxica?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adbc0e4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 1\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "La siguiente función **known** recibe una lista de tokens y regresa un conjunto de ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c639dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def known(words): \n",
    "    \"Subconjunto de palabras que aparecen en el diccionario WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ac581",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 2\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "* ¿Qué se concluye de los histogramas presentados antes de la reducción? \n",
    "* Encuentra el índice de riqueza léxica con el vocabulario reducido con `skip_min =  WORDS['dulcinea']` y `skip_max = WORDS['quijote']`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439846f0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 3. Creación de candidatos dado una palabra 𝑤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44951f9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Considera la función `edits1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e45a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"Palabras a una distancia _____ de edición de  `word`.\"\n",
    "    letters    = 'abcdefghijklmñnopqrstuvwxyzáéíóú'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set (deletes  + replaces + inserts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd92142",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 3\n",
    " </b></font>\n",
    "</summary>\n",
    "Completa lo siguiente:\n",
    "\n",
    "* La siguiente función `edits1` recibe una palabra $w$ y regresa un conjunto de palabras a distancia ____ de número de ediciones *deletes*, *replaces*, *inserts*. Completa también el comentario en el código.\n",
    "\n",
    "* Haz el bosquejo de corrida en papel de `edits1('dulcinea')`.\n",
    "\n",
    "* Al considerar textos en español, nuestro conjunto de letras (\"letters\") posee 32 símbolos. Así, con una cadena de caracteres de longitud $n$, podemos obtener:\n",
    "\n",
    "    * ____ cadenas al eliminar un símbolo de la cadena original\n",
    "    * ____ cadenas al realizar reemplazos \n",
    "    * ____ cadenas al insertar símbolos\n",
    "\n",
    "Esto es, `edits1` tiene $63n +32$ elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69ea0e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Considere ahora la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220ceb6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def edits2(word): \n",
    "    \"Palabras a una distancia _____ de edición de  `word`.\"\n",
    "    return set(e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed58eeb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8301a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'ayer' in edits2('aller')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2412101f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 4\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "* La siguiente función `edits2` recibe una palabra y regresa un conjunto de palabras a distancia ____ de número de ediciones *deletes*, *replaces*, *inserts*. Completa el comentario en el código.\n",
    "\n",
    "* ¿Cuántos elementos tiene `edits2(word)` si la palabra de entrada tiene longitud $n$?\n",
    "\n",
    "* Diseña la función `edits3(word)` ¿qué inconveniente tiene esta función?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871a4d7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Hasta aquí hemos creado una manera de generar posibles candidatos de corrección, pero claramente hay que pasar por el filtro `known` que creamos con nuestro diccionario de frecuencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba93bad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def candidates_version_preliminar(word): \n",
    "    \"Posibles canditados a ser la corrección de `word`.\"\n",
    "    return known(edits2(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee8169",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63aa44a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates_version_preliminar('af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a5c3d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates_version_preliminar('alf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33de47",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates_version_preliminar('dulcinea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a196efa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates_version_preliminar('dulsinea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a872eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates_version_preliminar('zancho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efab410",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates_version_preliminar('internet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bef727",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 4. Estimación del mejor candidato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ab52b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Recordar nuestra estrategia original era resolver:\n",
    "    $$c_{mejor~corrección} = argmax_{c \\in candidatos} P(c) P(w|c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a4e36",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Estrategia para calcular $P(c)$ (modelo de lenguaje)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb0a05",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Considera el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76723692",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "V = len(WORDS)\n",
    "N = sum(WORDS.values()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98001328",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La siguiente función`P` estima la probabilidad de una función en el lenguaje.  Notar que esta estimación está determinada completamente por la información recibida en el corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24838a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def P(word): \n",
    "    \"Probabilidad de `word`\"\n",
    "    return WORDS[word] / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9416216",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca03035",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[P('el'),P('quijote'),P('no'),P('usaba'),P('internet')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d926f6b5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Usualmente los cálculos se hacen con la log $P$  por cuestiones numéricas. Veremos como se ve esta distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb77065",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def logP(word): \n",
    "    \"Log-probabilidad de `word`\"\n",
    "    return np.log(P(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6e04d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def distribution(diccionario):\n",
    "    \"Distribucción de probabilidad de los valores de `diccionario`\"\n",
    "    return list(P(w) for w in diccionario)\n",
    "\n",
    "def distributionlog(diccionario):\n",
    "    \"Distribucción de log-probabilidad de los valores de `diccionario`\"\n",
    "    return list(logP(w) for w in diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4780f77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = px.violin(distribution(WORDS), title='Distribución de probabilidad modelo de lenguaje')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8add9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig = px.violin(distributionlog(WORDS), title='Distribución de log-probabilidad modelo de lenguaje')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4e9a2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 5\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "Justifica porqué:\n",
    "    $$argmax_{c \\in candidatos} P(c) P(w|c) = argmax_{c \\in candidatos} \\log P(c) \\log P(w|c).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8003ee",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Por otro lado, también se suelen utilizar suavizados para compensar la falta de información que siempre se va a tener aún \n",
    "cuando nuestro corpus sea inmenso o bien para hacer el sistema más robusto. Ejemplos en el modelo de lenguajes de n-gramas https://books.google.com/ngrams/.\n",
    "\n",
    "Un ejemplo sencillo es el suavizado de Laplace el cual depende de un parámetro $k$:\n",
    " $$P_{Lapace}(w,k)= \\frac{count(w)+k}{N+kV}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438a507",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def P_Laplace(word,k): \n",
    "    \"Probabilidad de `k`-Laplace de la palabra `word`\"\n",
    "    return (WORDS[word] + k) / (N + k * V)\n",
    "\n",
    "def distribution_Laplace(diccionario,k):\n",
    "    \"Distribucción de probabilidad  `k`-Laplace de los valores de `diccionario`\"\n",
    "    return list(P_Laplace(w,k) for w in diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48410bc2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 6\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "* Grafica la distribución de probabilidad de nuestro lenguaje respecto a diferentes estimaciones variando el parámetro $k$. Describe tus observaciones.\n",
    "* Demuestra que para cualquier $k$, la función $P_{Laplace}$ es efectivamente una distribución de probabilidad, es decir: $$\\sum_{w\\in Vocabulary} P_{Lapace}(w,k)=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa270c5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Estrategia para «calcular» $P(w|c)$ (modelo de error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c60fefe",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Como hemos establecido anteriormente no tenemos un corpus de errores frecuentes en el Reino de Castilla León del siglo XVII. Sin datos podemos construir un buen modelo de error ortográfico, sin embargo es posible construir un «modelo defectuoso» a partir de la premisa de que las palabras conocidas de distancia de edición 1 son mucho más probables que las palabras conocidas de distancia de edición 2, y mucho más probables que una de distancia de edición 3 y así sucesivamente. Además lo más probable de todo es que la palabra que una palabra conocida con distancia de edición 0. Entonces la idea es que en lugar de calcular $P(w|c)$ se genere  la lista de candidatos en orden de prioridad, dada $w$:\n",
    "\n",
    " * La palabra original, si es conocida; de lo contrario\n",
    " * La lista de palabras conocidas a una distancia de edición, si las hay; de lo contrario\n",
    " * La lista de palabras conocidas a una distancia de edición de dos, si las hay; de lo contrario\n",
    " * La palabra original, aunque no se conoce.\n",
    "\n",
    "Entonces no necesitamos multiplicar por un factor $P(w|c)$, porque cada candidato con la prioridad elegida tendrá la misma probabilidad (según nuestro modelo defectuoso). Lo anterior lo podemos lograr con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbce2e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def candidates(word): \n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6dd43",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70522e4f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('alf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb0169",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('dulcinea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2b6e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('dulsinea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287c625",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('zancho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b508e75",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('internet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159c87e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notar que  **word $\\in$known(edits1(word))$\\subset$known(edits2(word))** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830d759",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'internet' in known(edits1('internet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26e426",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "known(edits1('sancho')).issubset(known(edits1('sancho')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b580d72",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Estimación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6164a6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def correction(word): \n",
    "    \"Error más probable de `word`.\"\n",
    "    return max(candidates(word), key=logP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3936d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correction('af')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9c463",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correction('alf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db8712",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "candidates('internet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2185a5bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correction('zancho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e4c63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correction('pusiéredes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df71a90",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 5. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df20bc9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La siguiente prueba recibe como entrada una secuencia de entradas de la forma (`right`, `wrong`), ejecuta la funcion `correction` sobre cada error `wrong` y regresa la proporción de aciertos y fallas, y la cantidad de tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d521c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def spelltest(tests, verbose=False):\n",
    "    \"Ejecuta la corrección a la entrada `wrong` de  en todos los pares (`right`, `wrong`); reporta resultados.\"\n",
    "    import time\n",
    "    start = time.perf_counter()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w!= right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print(f'correction({wrong}) => {w} ({WORDS[w]}); expected {right} ({WORDS[right]})')\n",
    "\n",
    "    dt = time.perf_counter() - start\n",
    "    print(f\"{good/n:.0%} de {n} correciones ({unknown/n:.0%} desconocidos) a {n/dt:.0f} palabras por segundo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25a6e9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "El siguiente cógigo genera la lista de  (`right`, `wrong`) dados dos textos tokenizados de entrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e88f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def genera_pares(original,dictado):\n",
    "    \"Regresa lista de pares (`right`, `wrong`)\"\n",
    "    test = []\n",
    "    for i in range(len(original)):\n",
    "        if original[i] != dictado[i]:\n",
    "            test.append((original[i],dictado[i]))\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5024d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<summary>\n",
    "    <font size=\"2\" color=\"orange\"><b> Ejercicio 7\n",
    " </b></font>\n",
    "</summary>\n",
    "\n",
    "Para ejecutar esta función necesitamos un conjunto de prueba, ¡el cual no tenemos! Así que fabricaremos uno. Vamos a descargar las *Viage al Parnaso* también de Cervantes (tomado de https://www.gutenberg.org/cache/epub/16110/pg16110.txt) (archivo `viage_parmaso.txt`). Se tomarán las primeras palabras de este texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0873d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texto_prueba = re.sub(r'[^\\w+]|_', ' ', open('viage_parmaso.txt', encoding='utf-8').read().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc13cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texto_prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd7856",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Copia y pega un pedazo de algunas 15 palabras al azar y pégalo dentro de las comillas y después copia de manera rápida el texto que tienes arriba. Verifica el performance del corrector. Repite el procedimiento con varias veces y **escribe tus conclusiones**. Aquí unos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9bd6f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texto = 'peregrinas veras  si en ello adviertes y reparas  que es una este bagel de las mas dinas de admiracion'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f529f1e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "texto_dictado= 'peregrinas verás si en ello adviertees y reparasd que es una este bagel de las smas dinas de admiracion'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e3342",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test = genera_pares(texto,texto_dictado)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f477d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spelltest(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b747d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "correction('ambrosía')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d133cd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Trabajo futuro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c7c24",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Nuestro corrector tiene problemas en lidiar con palabras  desconocidas, una manera de arreglarlo\n",
    " es permitir que el resultado de la corrección sea una palabra que no hemos visto. Por ejemplo, \n",
    " si la entrada es `correctoniand`, una buena corrección sería cambiar la`s` final por una `o`, aunque \n",
    "`correctoniand` no esté en nuestro diccionario. Podríamos lograr esto con un modelo de lenguaje \n",
    "basado en componentes de palabras: quizás en sílabas o sufijos, pero es más fácil basarlo en secuencias de caracteres: secuencias comunes de 2, 3 y 4 letras.\n",
    "\n",
    "* El modelo de error $P(w|c)$  hasta ahora ha sido trivial: cuanto menor es la distancia de edición, menor es el error. Esto causa algunos problemas, como lo muestran los ejemplos siguientes. Primero, algunos casos en los que la corrección devuelve una palabra en la distancia de edición 1 cuando debería devolver una en la distancia de edición 2. Claramente, podríamos usar un mejor modelo del costo de las ediciones. Podríamos usar nuestra intuición para asignar costos más bajos por duplicar letras y cambiar una vocal por otra vocal (en comparación con un cambio de letra arbitrario), pero parece mejor recopilar datos: obtener un corpus de errores ortográficos y contar la probabilidad de que ocurran.\n",
    "\n",
    "* Una maner más eficaz es cambiar la interfaz a corrección para ver **más contexto**. Hasta ahora, la corrección sólo se centra en una palabra a la vez.  Para construir un modelo que analice varias palabras a la vez, necesitaremos muchos datos. Google ha publicado una base de datos con recuentos de palabras para todas las secuencias de hasta cinco palabras, recopiladas de un corpus de un billón de palabras (anteriormente dimos la liga para ejemplificar el suavizado), sin embargo, aunque existe una parte con $n$-gramas en español, todavía es muy pobre. Un corrector ortográfico que obtenga una precisión del 90% necesitará utilizar el contexto de las palabras circundantes para tomar una decisión y se requiere de acceso a datos (del orden de al menos $1x10^{12}$) y poder de cómputo y almacenamiento para gestionar y procesar la información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f97fb6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 📖\n",
    "<summary>\n",
    "    <font size=\"1\" color=\"gray\"><b>  Norvig, *How to Write a Spelling Corrector* https://norvig.com/spell-correct.html.  \n",
    " </b></font>\n",
    "<summary>\n",
    "    \n",
    "<summary>\n",
    "    <font size=\"1\" color=\"gray\"><b> Jurafsky and Martin https://home.cs.colorado.edu/~martin/slp.html.  \n",
    " </b></font>\n",
    "<summary>\n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
